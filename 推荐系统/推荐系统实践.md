# 评分预测问题

## 隐语义模型与矩阵分解模型

### 传统的SVD分解

- 首先用一个简单的方法补全稀疏评分矩阵
- 进行SVD分解
- 取最大的k个奇异值对应的行和列酉向量构成降维矩阵，重新获得评分矩阵
- 该方法计算复杂度太高

### Simon Funk的SVD分解(Latent Factor Model: LFM)

$$
\sum_{k=1}p_{u,k}q_{i,k}
$$



- 隐性反馈数据集：如何给用户生成负样本
  - 对每个用户，要保证正负样本的平衡
  - 采样负样本时，选取热门物品，而用户却没有行为的物品
  - 用户兴趣向量p和物品向量q
- 将评分矩阵分解为两个低维矩阵的乘积　　$R=P^TQ$

### 加入偏置项的LFM(BasicSVD)



### 考虑邻域影响的LFM(SVD++)



# 推荐系统的召回模型

## 协同过滤

### 基于用户的协同过滤

### 基于物品的协同过滤

### 基于模型的协同过滤(如矩阵分解)

## 向量化召回

- 主要通过模型来学习用户和物品的兴趣向量，并通过内积来计算用户和物品之间的相似性，从而得到最终的候选集。其中，比较经典的模型便是Youtube召回模型。在实际线上应用时，由于物品空间巨大，计算用户兴趣向量和所有物品兴趣向量的内积，耗时十分巨大，有时候会通过局部敏感Hash等方法来进行近似求解。

- 对于在线服务来说，有严格的性能要求，必须在几十毫秒内返回结果。因此，youtube没有重新跑一遍模型，而是通过保存用户兴趣embedding和视频兴趣embedding，通过最近邻搜索的方法得到top N的结果。该近似方法中的代表是局部敏感Hash方法

- 局部敏感哈希(Locality-Sensitive Hashing, LSH)

- 向量化召回是目前推荐召回核心发展的一代技术，但是它对模型结构做了很大的限制，必须要求模型围绕着用户和向量的embedding展开，同时在顶层进行内积运算得到相似性。在深度学习领域其实模型结构层出不穷，百花齐放，但是这样一个特定的结构实际上对模型能力造成了很大的限制。

## 深度树匹配

- 如果说向量化召回通过内积运算的方式打开了全库搜索的天花板，那么下一阶段应该是：能否设计一套全新的推荐算法框架，它允许容纳任意先进的模型而非限定内积形式，并且能够对全库进行更好的检索。**深度树匹配**，就是从这个视角出发做的技术探索。
- 协同过滤模型无法做到全局检索，而向量化模型对模型的结构进行了限制。深度树匹配模型解决了上述两个方面的限制，可以做到全局检索+使用先进模型。



## 基于深度学习(Item2Vec)



# 推荐系统的排序模型

## 浅层模型

- LR
- GBDT
- LR+GBDT

## 深层模型

- FM
- FFM
- DeepFFM
- Wide and Deep

  



